{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":68424,"databundleVersionId":7599097,"sourceType":"competition"}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-19T00:51:33.816323Z","iopub.execute_input":"2024-02-19T00:51:33.816963Z","iopub.status.idle":"2024-02-19T00:51:34.972270Z","shell.execute_reply.started":"2024-02-19T00:51:33.816937Z","shell.execute_reply":"2024-02-19T00:51:34.969591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:34.974297Z","iopub.execute_input":"2024-02-19T00:51:34.974783Z","iopub.status.idle":"2024-02-19T00:51:36.820289Z","shell.execute_reply.started":"2024-02-19T00:51:34.974749Z","shell.execute_reply":"2024-02-19T00:51:36.819230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/cs9856-spotify-classification-problem-2024/CS98XClassificationTrain.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:36.825930Z","iopub.execute_input":"2024-02-19T00:51:36.826589Z","iopub.status.idle":"2024-02-19T00:51:36.849971Z","shell.execute_reply.started":"2024-02-19T00:51:36.826558Z","shell.execute_reply":"2024-02-19T00:51:36.849123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:36.851014Z","iopub.execute_input":"2024-02-19T00:51:36.851477Z","iopub.status.idle":"2024-02-19T00:51:36.904567Z","shell.execute_reply.started":"2024-02-19T00:51:36.851451Z","shell.execute_reply":"2024-02-19T00:51:36.903676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:36.905572Z","iopub.execute_input":"2024-02-19T00:51:36.905843Z","iopub.status.idle":"2024-02-19T00:51:36.933093Z","shell.execute_reply.started":"2024-02-19T00:51:36.905818Z","shell.execute_reply":"2024-02-19T00:51:36.932136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['top genre'].fillna(\"adult standards\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:36.934240Z","iopub.execute_input":"2024-02-19T00:51:36.934509Z","iopub.status.idle":"2024-02-19T00:51:36.943605Z","shell.execute_reply.started":"2024-02-19T00:51:36.934486Z","shell.execute_reply":"2024-02-19T00:51:36.942493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.info())","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:36.945000Z","iopub.execute_input":"2024-02-19T00:51:36.945335Z","iopub.status.idle":"2024-02-19T00:51:36.962531Z","shell.execute_reply.started":"2024-02-19T00:51:36.945309Z","shell.execute_reply":"2024-02-19T00:51:36.961430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dropping object row\ntrain_data = train_data.drop(['title','Id','artist'],axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:36.964210Z","iopub.execute_input":"2024-02-19T00:51:36.964632Z","iopub.status.idle":"2024-02-19T00:51:36.972100Z","shell.execute_reply.started":"2024-02-19T00:51:36.964602Z","shell.execute_reply":"2024-02-19T00:51:36.970973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# correlation_matrix = train_data.corr()\n# plt.figure(figsize=(10, 8))\n# sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n# plt.title(\"Correlation Heatmap of Numeric Features\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:36.978719Z","iopub.execute_input":"2024-02-19T00:51:36.979748Z","iopub.status.idle":"2024-02-19T00:51:36.985002Z","shell.execute_reply.started":"2024-02-19T00:51:36.979710Z","shell.execute_reply":"2024-02-19T00:51:36.983852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"plot the correlation matrix and visualize it as a heatmap for the numeric columns in your dataset","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=train_data.dropna()\nprint(train_data.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:36.986297Z","iopub.execute_input":"2024-02-19T00:51:36.986662Z","iopub.status.idle":"2024-02-19T00:51:36.995849Z","shell.execute_reply.started":"2024-02-19T00:51:36.986629Z","shell.execute_reply":"2024-02-19T00:51:36.994828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label Encoder\nLabel Encoder is being used to convert non-interger values to integer values. Label encoding involes assigning a unique integer into each catogory in the variable.\nEach unique genre in the 'top genre' column is assigned a unique integer label.","metadata":{}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ntrain_data[\"top genre\"] = label_encoder.fit_transform(train_data[\"top genre\"])\n\n# Split data into features and target\nX = train_data.drop(columns=[\"top genre\"])\ny = train_data[\"top genre\"]","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:36.997159Z","iopub.execute_input":"2024-02-19T00:51:36.997633Z","iopub.status.idle":"2024-02-19T00:51:37.007427Z","shell.execute_reply.started":"2024-02-19T00:51:36.997600Z","shell.execute_reply":"2024-02-19T00:51:37.006489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:37.008583Z","iopub.execute_input":"2024-02-19T00:51:37.009013Z","iopub.status.idle":"2024-02-19T00:51:37.022946Z","shell.execute_reply.started":"2024-02-19T00:51:37.008980Z","shell.execute_reply":"2024-02-19T00:51:37.022030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Standardization\nStandard scalar is used for standardization as it ensures each feature has a mean of 0 and standard deviation of 1, making them comparable and preventing features with larger scales from dominating the model's learning process.\nThis scaler is first fitted into the training data (X_train) and then applied to both the training and testing data to avoid data leakage.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:37.024457Z","iopub.execute_input":"2024-02-19T00:51:37.024787Z","iopub.status.idle":"2024-02-19T00:51:37.039903Z","shell.execute_reply.started":"2024-02-19T00:51:37.024754Z","shell.execute_reply":"2024-02-19T00:51:37.038995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter tuning\nIt is a crucial step in the machine learning workflow where you search for the optimal hyperparameters for your model. They are parameteres that are set prior to the training process and are not learned from the data.\n\nTo perform hyperparameter tuning, the code can be enhanced with techniques such as **GridSearchCV**, which exhaustively searches over a specific parameter grid, evaluvating the model performance using cross-validation.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\n\n\n\nrf_classifier = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=42)\nrf_classifier.fit(X_train_scaled, y_train)\n\n\n\n\ny_pred = rf_classifier.predict(X_test_scaled)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:37.041304Z","iopub.execute_input":"2024-02-19T00:51:37.041872Z","iopub.status.idle":"2024-02-19T00:51:37.601269Z","shell.execute_reply.started":"2024-02-19T00:51:37.041838Z","shell.execute_reply":"2024-02-19T00:51:37.600239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nbase_estimator = DecisionTreeClassifier(random_state=42)\n\n\nbagging_classifier = BaggingClassifier(estimator=base_estimator, n_estimators=30, random_state=42)\nbagging_classifier.fit(X_train_scaled, y_train)\n\n\ny_pred_bagging = bagging_classifier.predict(X_test_scaled)\naccuracy = accuracy_score(y_test, y_pred_bagging)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:37.602516Z","iopub.execute_input":"2024-02-19T00:51:37.602832Z","iopub.status.idle":"2024-02-19T00:51:37.823937Z","shell.execute_reply.started":"2024-02-19T00:51:37.602804Z","shell.execute_reply":"2024-02-19T00:51:37.822704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Initialize base estimator (e.g., Decision Tree)\nbase_estimator = DecisionTreeClassifier(max_depth=1, random_state=42)\n\n# Initialize and train AdaBoost Classifier\nadaboost_classifier = AdaBoostClassifier(estimator=base_estimator, n_estimators=100, random_state=42)\nadaboost_classifier.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred_adaboost = adaboost_classifier.predict(X_test_scaled)\n\naccuracy = accuracy_score(y_test, y_pred_adaboost)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:37.825466Z","iopub.execute_input":"2024-02-19T00:51:37.825867Z","iopub.status.idle":"2024-02-19T00:51:38.211080Z","shell.execute_reply.started":"2024-02-19T00:51:37.825830Z","shell.execute_reply":"2024-02-19T00:51:38.209954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\n# Initialize SVM classifier\nsvm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n\n# Train the SVM classifier\nsvm_classifier.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred_svm = svm_classifier.predict(X_test_scaled)\n\n# Calculate accuracy\naccuracy_svm = accuracy_score(y_test, y_pred_svm)\nprint(\"Accuracy:\", accuracy_svm)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:38.212392Z","iopub.execute_input":"2024-02-19T00:51:38.212826Z","iopub.status.idle":"2024-02-19T00:51:38.281631Z","shell.execute_reply.started":"2024-02-19T00:51:38.212785Z","shell.execute_reply":"2024-02-19T00:51:38.280593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_params = grid_search.best_params_\n# print(\"Best Parameters:\", best_params)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:38.282866Z","iopub.execute_input":"2024-02-19T00:51:38.283744Z","iopub.status.idle":"2024-02-19T00:51:38.287246Z","shell.execute_reply.started":"2024-02-19T00:51:38.283716Z","shell.execute_reply":"2024-02-19T00:51:38.286236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n\n# Make predictions\ny_pred = rf_classifier.predict(X_test_scaled)\n\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:38.288622Z","iopub.execute_input":"2024-02-19T00:51:38.288928Z","iopub.status.idle":"2024-02-19T00:51:38.319074Z","shell.execute_reply.started":"2024-02-19T00:51:38.288904Z","shell.execute_reply":"2024-02-19T00:51:38.318174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data =  pd.read_csv('/kaggle/input/cs9856-spotify-classification-problem-2024/CS98XClassificationTest.csv')\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:38.320303Z","iopub.execute_input":"2024-02-19T00:51:38.320567Z","iopub.status.idle":"2024-02-19T00:51:38.364866Z","shell.execute_reply.started":"2024-02-19T00:51:38.320545Z","shell.execute_reply":"2024-02-19T00:51:38.364001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = test_data.drop(['title','Id','artist'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:38.365841Z","iopub.execute_input":"2024-02-19T00:51:38.366124Z","iopub.status.idle":"2024-02-19T00:51:38.372042Z","shell.execute_reply.started":"2024-02-19T00:51:38.366083Z","shell.execute_reply":"2024-02-19T00:51:38.371156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:38.373093Z","iopub.execute_input":"2024-02-19T00:51:38.373387Z","iopub.status.idle":"2024-02-19T00:51:38.385642Z","shell.execute_reply.started":"2024-02-19T00:51:38.373363Z","shell.execute_reply":"2024-02-19T00:51:38.384662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\ntest_data_scaled= scaler.fit_transform(test_data)\ntest_data_scaled= scaler.transform(test_data)\ny_pred_sub = rf_classifier.predict(test_data_scaled)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:38.387099Z","iopub.execute_input":"2024-02-19T00:51:38.387776Z","iopub.status.idle":"2024-02-19T00:51:38.419875Z","shell.execute_reply.started":"2024-02-19T00:51:38.387741Z","shell.execute_reply":"2024-02-19T00:51:38.419182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Iterative Refinement\nIt is a fundamental aspect of the machine learning workflow , especially in classification problems, where the goal is to classify data points into predefined catogories or classes. It is a dynamic process that involves continous improvement and adjustment of various components within the machine learning pipeline.","metadata":{}},{"cell_type":"code","source":"genre_labels = label_encoder.inverse_transform(y_pred_sub)\n\nprint(genre_labels)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:38.420850Z","iopub.execute_input":"2024-02-19T00:51:38.421100Z","iopub.status.idle":"2024-02-19T00:51:38.426682Z","shell.execute_reply.started":"2024-02-19T00:51:38.421079Z","shell.execute_reply":"2024-02-19T00:51:38.425646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data =  pd.read_csv('/kaggle/input/cs9856-spotify-classification-problem-2024/CS98XClassificationTest.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:38.428142Z","iopub.execute_input":"2024-02-19T00:51:38.428550Z","iopub.status.idle":"2024-02-19T00:51:38.439934Z","shell.execute_reply.started":"2024-02-19T00:51:38.428521Z","shell.execute_reply":"2024-02-19T00:51:38.438986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df=pd.DataFrame({'Id':test_data['Id'],'top genre':genre_labels})\nsubmission_df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T00:51:38.440998Z","iopub.execute_input":"2024-02-19T00:51:38.441403Z","iopub.status.idle":"2024-02-19T00:51:38.448703Z","shell.execute_reply.started":"2024-02-19T00:51:38.441369Z","shell.execute_reply":"2024-02-19T00:51:38.447750Z"},"trusted":true},"execution_count":null,"outputs":[]}]}